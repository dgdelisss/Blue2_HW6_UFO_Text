{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextMining.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dgdelisss/Blue2_HW6_UFO_Text/blob/master/TextMining.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ZP1jVwz1lbtZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Project Description:**\n",
        "We will analyze data on reported incidents of UFO sightings. Utilizing data collected by an organization dedicated to this topic, we will apply topic clustering techniques to identify commonalities among these sightings and interpret the results to provide a summary of the major themes of these reports. After clustering among the full dataset, we will then focus on comparing UFO sightings in California, Arizona, and Nevada again using clustering to investigate their similarities and differences.  \n",
        "\n",
        "**Analysis: **\n",
        "We will perform topic clustering on the text column from our dataset to identify major topics of discussion. We will then use this clustering to analyze any commonalities or anomalies based on descriptors of UFO shape, size, etc. We’ll start with a cluster analysis of the full dataset, and then narrow the focus to comparing sightings exclusively in California, Nevada, and Arizona.\n",
        "\n",
        "**Deliverables: **\n",
        "We will provide the following deliverables at the end of the project:\n",
        "A dataset containing reports of UFO sightings\n",
        "A set of insights derived from the dataset\n",
        "A short in-class presentation of our findings, discussions of their meaning, and general “lessons learned” from our project. \n"
      ]
    },
    {
      "metadata": {
        "id": "taTJ6Lwgz5sr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Packages and Installations:"
      ]
    },
    {
      "metadata": {
        "id": "_pzUFQSLuSsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "eb84e193-c9f1-4480-fcff-fc41189111e1"
      },
      "cell_type": "code",
      "source": [
        "#installs any packages not available by default\n",
        "!pip install gensim\n",
        "!pip install wordcloud\n",
        "%time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.6MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 15.1MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/61/99519865ee175a95cf5a2922265240518202a9f07806a29173085ced93c0/boto3-1.9.26-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 27.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Collecting botocore<1.13.0,>=1.12.26 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/77/3c2b1aeba40f2d03bc023630c6285baef93120035d05b5c60ce3307be510/botocore-1.12.26-py2.py3-none-any.whl (4.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.7MB 9.0MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 24.9MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.26->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.26->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 24.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.9.26 botocore-1.12.26 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n",
            "Collecting wordcloud\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/af/849edf14d573eba9c8082db898ff0d090428d9485371cc4fe21a66717ad2/wordcloud-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (361kB)\n",
            "\u001b[K    100% |████████████████████████████████| 368kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud) (0.46)\n",
            "Installing collected packages: wordcloud\n",
            "Successfully installed wordcloud-1.5.0\n",
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 9.54 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NQsEJ6a8jp3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7a1a3741-5e70-4b8b-c2ac-71dff71c6e3e"
      },
      "cell_type": "code",
      "source": [
        "#importing packages neeeded for Text Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import sklearn\n",
        "import gensim\n",
        "import re\n",
        "import string\n",
        "import wordcloud\n",
        "import os\n",
        "%time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 9.54 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ouc9eqz9njuJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ddfa637d-9667-4524-f43f-6aff8917b3fd"
      },
      "cell_type": "code",
      "source": [
        "##Specific Text Mining Features from SKLEARN\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "#Other specific useful packages\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "%time"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 9.78 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xJ7XIEoEszpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "27a95369-9214-48b4-c61d-40184537b9f4"
      },
      "cell_type": "code",
      "source": [
        "#Downloading features from nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "%time"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 9.78 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h7Q2-WCY0CTS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# User Defined Functions:"
      ]
    },
    {
      "metadata": {
        "id": "AXqWwedL8cMc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Flatten Function (This will collapse a list of lists into just one list)\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cKAvXZF6R05e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Stringer\n",
        "\n",
        "def Stringer(list):\n",
        "  new_list = []\n",
        "  for i in list:\n",
        "    new = str(i)\n",
        "    new_list.append(new)\n",
        "  return(new_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1RrrOrszRa3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Term Vector Function\n",
        "def Term_Vectors(doc):\n",
        "  punc = re.compile( '[%s]' % re.escape( string.punctuation ) )\n",
        "  term_vec = [ ]\n",
        "\n",
        "  for d in doc:\n",
        "      d = str(d)\n",
        "      d = d.lower()\n",
        "      d = punc.sub( '', d )\n",
        "      term_vec.append( nltk.word_tokenize( d ) )\n",
        "\n",
        "  return(term_vec)\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bBd0yw1h1BPu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Stop Word Function\n",
        "def Stop_Word(term_vec, stop_words = nltk.corpus.stopwords.words( 'english' )):\n",
        "\n",
        "  for i in range( 0, len( term_vec ) ):\n",
        "      \n",
        "      term_list = [ ]\n",
        "\n",
        "      for term in term_vec[i]:\n",
        "          if term not in stop_words:\n",
        "              term_list.append( term )\n",
        "\n",
        "      term_vec[i] = term_list\n",
        "\n",
        "  return(term_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMRTelCwQo02",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Porter Stem Function\n",
        "\n",
        "def Porter_Stem(term_vec):\n",
        "  porter = nltk.stem.porter.PorterStemmer()\n",
        "\n",
        "  for i in range( 0, len( term_vec ) ):\n",
        "    for j in range( 0, len( term_vec[ i ] ) ):\n",
        "      term_vec[ i ][ j ] = porter.stem( term_vec[ i ][ j ] )\n",
        "\n",
        "  return(term_vec)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BwY2bLzrABj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Lemmatizer Function\n",
        "def lemmatizer(term_vec):\n",
        "  for i in range( 0, len( term_vec ) ):\n",
        "    for j in range( 0, len( term_vec[ i ] ) ):\n",
        "      try: pos = str(wn.synsets(j)[0].pos())\n",
        "      except: pos = \"n\"\n",
        "      term_vec[i][j] = str(WordNetLemmatizer().lemmatize(term_vec[i][j],pos))\n",
        "  return(term_vec)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJkQYZDM1R6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Basic Word Cloud Function\n",
        "\n",
        "def show_wordcloud(data, title = None):\n",
        "    wordcloud = WordCloud(\n",
        "        background_color='white',\n",
        "        max_words=50,\n",
        "        max_font_size=40, \n",
        "        scale=3,\n",
        "        random_state=1 # chosen at random by flipping a coin; it was heads\n",
        "    ).generate(str(data))\n",
        "\n",
        "    fig = plt.figure(1, figsize=(12, 12))\n",
        "    plt.axis('off')\n",
        "    if title: \n",
        "        fig.suptitle(title, fontsize=20)\n",
        "        fig.subplots_adjust(top=2.3)\n",
        "\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BO3Lpnc90HJc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initial Data Importation and Cleaning:"
      ]
    },
    {
      "metadata": {
        "id": "8_kzdFuYsIIU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#imports ufo dataset from our data.world repo\n",
        "ufoset = pd.read_csv('https://query.data.world/s/t5l7slkbhurybmuxkfgncobbaknf7i')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDQ6U_bymFTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "001c4840-0079-42a4-8ae8-51501492a310"
      },
      "cell_type": "code",
      "source": [
        "#subsets data by selected states, removes every column but State and Text\n",
        "states = [\"CA\",\"NV\",\"AR\",\"NM\", \"NC\"]\n",
        "subset_ufoset = ufoset.loc[ufoset['state'].isin(states)]\n",
        "\n",
        "encounters = subset_ufoset[['text','state']]\n",
        "\n",
        "#New datasets for each state\n",
        "CA_encounters = encounters.loc[ufoset['state'] == \"CA\"]\n",
        "NV_encounters = encounters.loc[ufoset['state'] == \"NV\"]\n",
        "AR_encounters = encounters.loc[ufoset['state'] == \"AR\"]\n",
        "NM_encounters = encounters.loc[ufoset['state'] == \"NM\"]\n",
        "NC_encounters = encounters.loc[ufoset['state'] == \"NC\"]\n",
        "\n",
        "#Word Vectors\n",
        "All_States = ufoset['text'].values.tolist()\n",
        "SelectStates_vect = encounters['text'].values.tolist()\n",
        "CA_vect = CA_encounters['text'].values.tolist()\n",
        "NV_vect = NV_encounters['text'].values.tolist()\n",
        "AR_vect = AR_encounters['text'].values.tolist()\n",
        "NM_vect = NM_encounters['text'].values.tolist()\n",
        "NC_vect = NC_encounters['text'].values.tolist()\n",
        "\n",
        "print(\"Lists created.\")\n",
        "%time"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lists created.\n",
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.3 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1UN_s-8WvEz3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Begin Text Processing with Term Vectors, Stopwords, and Stemming:"
      ]
    },
    {
      "metadata": {
        "id": "A8OMUtSQuLTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2b4c5194-33be-40e5-a3f4-ee933d21084b"
      },
      "cell_type": "code",
      "source": [
        "#Creates Term Vectors for all word vectors\n",
        "\n",
        "All_term = Term_Vectors(All_States)\n",
        "SelectStates_term = Term_Vectors(SelectStates_vect)\n",
        "CA_term = Term_Vectors(CA_vect)\n",
        "NV_term = Term_Vectors(NV_vect)\n",
        "AR_term =Term_Vectors(AR_vect)\n",
        "NM_term =Term_Vectors(NM_vect)\n",
        "NC_term =Term_Vectors(NC_vect)\n",
        "\n",
        "print(\"Term Vectors  Complete.\")\n",
        "%time"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Term Vectors  Complete.\n",
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 10.3 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WlKaOxc1lVSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f73b0557-e0b4-40ef-c635-aff879b80f31"
      },
      "cell_type": "code",
      "source": [
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "custom_words = ['summary','SUMMARY']\n",
        "stopword += custom_words\n",
        "\n",
        "print(\"Stop Words Created.\")\n",
        "%time"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stop Words Created.\n",
            "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
            "Wall time: 13.4 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZTQqrsgLuPp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f5df6f7f-1c2d-4634-c0a0-ecb0d7186ddd"
      },
      "cell_type": "code",
      "source": [
        "#Stop Word filter for all Vectors\n",
        "All_stop = Stop_Word(All_term,stopword)\n",
        "SelectStates_stop = Stop_Word(SelectStates_term,stopword)\n",
        "CA_stop = Stop_Word(CA_term,stopword)\n",
        "NV_stop = Stop_Word(NV_term,stopword)\n",
        "AR_stop = Stop_Word(AR_term,stopword)\n",
        "NM_stop = Stop_Word(NM_term,stopword)\n",
        "NC_stop = Stop_Word(NC_term,stopword)\n",
        "\n",
        "print(\"Stop Words filter Applied to Term Vectors.\")\n",
        "%time"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stop Words filter Applied to Term Vectors.\n",
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.78 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rfx5NXozq7jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c12da12b-2db6-421b-9a39-ef5483793367"
      },
      "cell_type": "code",
      "source": [
        "#Lemmatizing for All Vectors\n",
        "#Results look way cleaner than porter stemming\n",
        "\n",
        "All_lem = lemmatizer(All_stop)\n",
        "SelectStates_lem = lemmatizer(SelectStates_stop)\n",
        "CA_lem = lemmatizer(CA_stop)\n",
        "NV_lem = lemmatizer(NV_stop)\n",
        "AR_lem = lemmatizer(AR_stop)\n",
        "NM_lem = lemmatizer(NM_stop)\n",
        "NC_lem = lemmatizer(NC_stop)\n",
        "\n",
        "print(\"Lemmatization Complete.\")\n",
        "%time"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemmatization Complete.\n",
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 10 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZqGoVJ1A69cJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3ce88504-5686-4d37-d746-73d60c66be50"
      },
      "cell_type": "code",
      "source": [
        "#Will probably need to refilter the vectors after stemming - not sure how much filter terms are needed yet\n",
        "nextfilter = [\"'\",\"-\",\"look\",\"saw\",\"like\",\"seen\",\"see\",\"could\",\"would\",\"also\",\"got\",\"said\",\"seem\",\"go\",\"well\",\"even\"]\n",
        "\n",
        "All_filt = Stop_Word(All_lem,nextfilter)\n",
        "SelectStates_filt = Stop_Word(SelectStates_lem,nextfilter)\n",
        "CA_filt = Stop_Word(CA_lem,nextfilter)\n",
        "NV_filt = Stop_Word(NV_lem,nextfilter)\n",
        "AR_filt = Stop_Word(AR_lem,nextfilter)\n",
        "NM_filt = Stop_Word(NM_lem,nextfilter)\n",
        "NC_filt = Stop_Word(NC_lem,nextfilter)\n",
        "\n",
        "print(\"Text Filtering Complete\")\n",
        "%time"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Filtering Complete\n",
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 9.54 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0_jxm2gtHhYy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d3e1c8bb-90e5-4bec-f727-89e7db6de189"
      },
      "cell_type": "code",
      "source": [
        "#Setting Up Vocab Lists\n",
        "\n",
        "Select_vdict = {'index': SelectStates_filt,'word': SelectStates_term}\n",
        "Select_vocab = pd.DataFrame(Select_vdict)\n",
        "Select_vocab = Select_vocab.set_index('index')\n",
        "\n",
        "print('there are ' + str(Select_vocab.shape[0]) + ' items in Select_vocab')\n",
        "\n",
        "print(\"Vocab Vectors Complete\")\n",
        "%time"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 18947 items in Select_vocab\n",
            "Vocab Vectors Complete\n",
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 14.3 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cFJ6gmTYYTl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a39f542-5b33-4879-f23d-df8ce355e57e"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18947"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "s0JPYET_zVJp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#tfidf Vectorization & K-Means Clustering"
      ]
    },
    {
      "metadata": {
        "id": "N2f0e9HhzR4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "38cf80d5-c783-45a7-bb75-85cc08363606"
      },
      "cell_type": "code",
      "source": [
        "All_tfidf = TfidfVectorizer(All_filt, decode_error = \"replace\")\n",
        "SelectStates_tfidf = TfidfVectorizer(SelectStates_filt, decode_error = \"replace\")\n",
        "CA_tfidf = TfidfVectorizer(CA_filt, decode_error = \"replace\")\n",
        "NV_tfidf = TfidfVectorizer(NV_filt, decode_error = \"replace\")\n",
        "AR_tfidf = TfidfVectorizer(AR_filt, decode_error = \"replace\")\n",
        "NM_tfidf = TfidfVectorizer(NM_filt, decode_error = \"replace\")\n",
        "NC_tfidf = TfidfVectorizer(NC_filt, decode_error = \"replace\")\n",
        "\n",
        "print(\"Tfidf Vectors Complete.\")\n",
        "%time"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tfidf Vectors Complete.\n",
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 10 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7YOPO660Dn7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8132e80f-de16-4597-fa2a-a5ec2c5d264c"
      },
      "cell_type": "code",
      "source": [
        "##Document Similarity Matrices\n",
        "\n",
        "#All_matrix = All_tfidf.fit_transform(ufoset['text'].values.astype('U'))\n",
        "SelectStates_matrix = SelectStates_tfidf.fit_transform(encounters['text'].values.astype('U'))\n",
        "CA_matrix = CA_tfidf.fit_transform(CA_encounters['text'].values.astype('U'))\n",
        "CA_matrix = CA_tfidf.fit_transform(CA_encounters['text'].values.astype('U'))\n",
        "NV_matrix = NV_tfidf.fit_transform(NV_encounters['text'].values.astype('U'))\n",
        "AR_matrix = AR_tfidf.fit_transform(AR_encounters['text'].values.astype('U'))\n",
        "NM_matrix = NM_tfidf.fit_transform(NM_encounters['text'].values.astype('U'))\n",
        "NC_matrix = NC_tfidf.fit_transform(NC_encounters['text'].values.astype('U'))\n",
        "\n",
        "print(\"Similarity Matrices Complete.\")\n",
        "%time"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity Matrices Complete.\n",
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.54 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9qIkHPzHfx9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0bd9f17f-4e7e-497b-e48a-84a8a3cee5a6"
      },
      "cell_type": "code",
      "source": [
        "#Get term names\n",
        "#All_terms = All_tfidf.get_feature_names()\n",
        "select_terms = SelectStates_tfidf.get_feature_names()\n",
        "CA_terms = CA_tfidf.get_feature_names()\n",
        "NV_terms = NV_tfidf.get_feature_names()\n",
        "AR_terms = AR_tfidf.get_feature_names()\n",
        "NM_terms = NM_tfidf.get_feature_names()\n",
        "NC_terms = NC_tfidf.get_feature_names()\n",
        "\n",
        "print(\"Term Names Complete.\")\n",
        "%time"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Term Names Complete.\n",
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 9.06 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uEqcfZ_f73Eb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "53079c93-6367-43e6-96c0-00c9f28f3b0c"
      },
      "cell_type": "code",
      "source": [
        "#Pairwise Similaritiy Distances Calculation\n",
        "\n",
        "#All_dist = 1 - cosine_similarity(All_matrix)\n",
        "SelectStates_dist = 1 - cosine_similarity(SelectStates_matrix)\n",
        "CA_dist = 1 - cosine_similarity(CA_matrix)\n",
        "NV_dist = 1 - cosine_similarity(NV_matrix)\n",
        "AR_dist = 1 - cosine_similarity(AR_matrix)\n",
        "NM_dist = 1 - cosine_similarity(NM_matrix)\n",
        "NC_dist = 1 - cosine_similarity(NC_matrix)\n",
        "\n",
        "print(\"Pairwise Complete Distances Calculated\")\n",
        "%time"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pairwise Complete Distances Calculated\n",
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 10.5 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVq33TlE1weL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6d485f3d-5d06-4bf2-cad5-5cf58815dbe9"
      },
      "cell_type": "code",
      "source": [
        "## KMeans Clustering with n = 5\n",
        "\n",
        "#All_kmeans = KMeans(n_clusters=5,random_state =0).fit(All_matrix)\n",
        "SelectStates_kmeans = KMeans(n_clusters=5,random_state =0).fit(SelectStates_matrix)\n",
        "CA_kmeans = KMeans(n_clusters=5,random_state =0).fit(CA_matrix)\n",
        "NV_kmeans = KMeans(n_clusters=5,random_state =0).fit(NV_matrix)\n",
        "AR_kmeans = KMeans(n_clusters=5,random_state =0).fit(AR_matrix)\n",
        "NM_kmeans = KMeans(n_clusters=5,random_state =0).fit(NM_matrix)\n",
        "NC_kmeans = KMeans(n_clusters=5,random_state =0).fit(NC_matrix)\n",
        "\n",
        "print(\"K-Means Clustering Complete\")\n",
        "%time"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-Means Clustering Complete\n",
            "CPU times: user 14 µs, sys: 2 µs, total: 16 µs\n",
            "Wall time: 14.8 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NHu_eIGT6KJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "505084fa-219f-4c7e-be8a-e590d1aed017"
      },
      "cell_type": "code",
      "source": [
        "#Get Cluster Labels\n",
        "\n",
        "#All_States_clusters = All_kmeans.labels_.tolist()\n",
        "SelectStates_clusters = SelectStates_kmeans.labels_.tolist()\n",
        "CA_clusters = CA_kmeans.labels_.tolist()\n",
        "NV_clusters = NV_kmeans.labels_.tolist()\n",
        "AR_clusters = AR_kmeans.labels_.tolist()\n",
        "NM_clusters = NM_kmeans.labels_.tolist()\n",
        "NC_clusters = NC_kmeans.labels_.tolist()\n",
        "\n",
        "print(\"Cluster Labels Complete.\")\n",
        "%time"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster Labels Complete.\n",
            "CPU times: user 15 µs, sys: 2 µs, total: 17 µs\n",
            "Wall time: 23.6 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sKly3aJI8xvK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Select_State = {'index': SelectStates_clusters,'clusters': SelectStates_clusters, 'State': encounters['state'], \"Text\":encounters['text'] }\n",
        "Select_Frame = pd.DataFrame(Select_State)\n",
        "Select_Frame = Select_Frame.set_index('index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rg4yc5OgKuCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1b5f4e4d-2798-4723-a2c1-02019819a5bb"
      },
      "cell_type": "code",
      "source": [
        "Select_Frame['clusters'].value_counts() #number of 'encounters' per cluster (clusters from 0 to 4)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    5440\n",
              "0    4842\n",
              "3    4522\n",
              "1    2714\n",
              "2    1429\n",
              "Name: clusters, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "qSXnrIL-Jr0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a39e61d5-dc08-4335-895c-c821a65b1581"
      },
      "cell_type": "code",
      "source": [
        "order_centroids[1,:5]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([36817, 36933,  4053, 40388, 37357])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "3GP-j6eDYlTe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SelectStates_clusters[36817]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMefOPGsZsMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfb4ca16-be8c-4ce4-baf0-2a524a728b94"
      },
      "cell_type": "code",
      "source": [
        "Select_vocab.items()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object DataFrame.iteritems at 0x7ff52ce57fc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "Ml5egJEhFXu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0bd32859-626c-4ff0-c365-28d8d7aed5d4"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "print(\"Top terms per cluster:\")\n",
        "print(\"\")\n",
        "#sort cluster centers by proximity to centroid\n",
        "order_centroids = SelectStates_kmeans.cluster_centers_.argsort()[:, ::-1] \n",
        "\n",
        "for i in range(5):\n",
        "    print(\"Cluster words:\", i, \":\", end='')\n",
        "    \n",
        "    for ind in order_centroids[i, :5]: #replace 6 with n words per cluster\n",
        "        \n",
        "        #print(Select_vocab.iloc[select_terms[ind]], end =\",\")\n",
        "        #print(list(Select_vocab.keys())[list(Select_vocab.values()).index(select_terms[ind])],end =\",\")\n",
        "        print(select_terms[ind], end = \",\")\n",
        "        \n",
        "print(\"\")\n",
        "print(\"\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top terms per cluster:\n",
            "\n",
            "Cluster words: 0 :the,and,to,was,it,Cluster words: 1 :the,they,and,were,to,Cluster words: 2 :provides,information,elects,anonymous,remain,Cluster words: 3 :it,the,was,and,to,Cluster words: 4 :the,and,it,in,to,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b_H54IT3a_WV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Multidimension Scaling\n",
        "\n",
        "import os  # for os.path.basename\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "from sklearn.manifold import MDS\n",
        "\n",
        "MDS()\n",
        "\n",
        "# convert two components as we're plotting points in a two-dimensional plane\n",
        "# \"precomputed\" because we provide a distance matrix\n",
        "# we will also specify `random_state` so the plot is reproducible.\n",
        "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
        "\n",
        "pos = mds.fit_transform(SelectStates_dist)  # shape (n_components, n_samples)\n",
        "\n",
        "xs, ys = pos[:, 0], pos[:, 1]\n",
        "print()\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vs5ceJ89zud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experimental Code for Figureing out Next Steps:"
      ]
    },
    {
      "metadata": {
        "id": "45gpAyFM7fZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a294d971-614f-4430-abb0-6c31967d6da1"
      },
      "cell_type": "code",
      "source": [
        "#Flattening List of Lists of Each State - Might be useful for State Comparisons\n",
        "All_flat = flatten(All_filt)\n",
        "CA_flat = flatten(CA_filt)\n",
        "NV_flat = flatten(NV_filt)\n",
        "AR_flat = flatten(AR_filt)\n",
        "NM_flat = flatten(NM_filt)\n",
        "\n",
        "print(\"Flattened...\")\n",
        "%time"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flattened...\n",
            "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
            "Wall time: 8.82 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xfCCyci3-yUl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creates a list of lists of our 4 states \n",
        "States = [CA_flat,NV_flat,AR_flat,NM_flat]\n",
        "%time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wtDgaDbj8vxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6256bb48-3b40-4b58-a2b5-1506b70e3250"
      },
      "cell_type": "code",
      "source": [
        "#Basic Exploration of Word Counts\n",
        "Counter(All_flat).most_common(50)\n",
        "%time"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.3 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gDCbaS-5vJSs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "All_kmeans.shape()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}